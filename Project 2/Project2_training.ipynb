{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Notebook**"
      ],
      "metadata": {
        "id": "OpLDzkOcyWuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from scipy.stats import randint\n",
        "import pickle  # For saving the model and scaler"
      ],
      "metadata": {
        "id": "oVSf4mGmjLBd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Getting the Data Ready:**\n",
        "- **Loading the Data:** The code starts by loading a dataset that contains information about houses and their prices. Think of it as opening up a spreadsheet full of house details.\n",
        "- **Cleaning and Organizing:** It then cleans up the data a bit.\n",
        "  - It converts the 'date' column into a format the computer understands as a date.\n",
        "  - It extracts the year and month from the date of the sale and stores them in separate columns.\n",
        "  - Removes the \"id\" and \"date\" columns, which aren't helpful for predicting prices.\n",
        "  - It calculates the age of each house based on the year it was built and the sale year.\n",
        "  - Creates a new column indicating whether the house has been renovated or not."
      ],
      "metadata": {
        "id": "WNghbHt6KvJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/kc_house_data.csv\")\n",
        "\n",
        "# Data Preprocessing (same as before)\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df['sale_year'] = df['date'].dt.year\n",
        "df['sale_month'] = df['date'].dt.month\n",
        "df = df.drop(['id', 'date'], axis=1)  # Drop 'id' and 'date'\n",
        "\n",
        "df['age'] = df['sale_year'] - df['yr_built']\n",
        "df['renovated'] = df['yr_renovated'].apply(lambda x: 1 if x > 0 else 0)"
      ],
      "metadata": {
        "id": "aNcRBa5WLeZd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Selecting the Important Features:**\n",
        "- **Choosing the Right Columns:** The code selects a specific set of columns (features) that it believes are most important for predicting house prices. These columns include things like number of bedrooms, square footage, location, age, and whether the house has a waterfront view."
      ],
      "metadata": {
        "id": "r3IozwvGKuuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Selection\n",
        "features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront',\n",
        "            'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built',\n",
        "            'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15',\n",
        "            'age', 'renovated', 'sale_year', 'sale_month']\n",
        "\n",
        "X = df[features]\n",
        "y = df['price']"
      ],
      "metadata": {
        "id": "vuijkdVlLu6v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Splitting the Data:**\n",
        "- **Creating Training and Testing Sets:** The code divides the data into two parts: a training set and a testing set. The training set is used to teach the model how to predict prices, and the testing set is used to evaluate how well the model has learned. Think of it as using one set of practice problems to learn and a separate set to take the final exam."
      ],
      "metadata": {
        "id": "4v7MDU5AKv-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "L7h0puhVLwef"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Scaling the Data:**\n",
        "- **Normalizing the Values:** The code uses a \"scaler\" to adjust the range of values in the data. This is important because some features might have very large values (like square footage), while others have very small values (like number of bedrooms). Scaling ensures that all features are on a similar scale, which helps the model learn more effectively."
      ],
      "metadata": {
        "id": "mlZcR2FOK8SZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "UMzNccI_L5PQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Hyperparameter Tuning:**\n",
        "- **Finding the Best Settings:** The code uses a technique called **\"Randomized Search\"** to find the best settings (hyperparameters) for the Random Forest model. It tries out different combinations of settings and sees which ones produce the best results. This is like trying different combinations of ingredients to find the perfect recipe."
      ],
      "metadata": {
        "id": "y8ZUqLLfK7lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Tuning (RandomizedSearchCV)\n",
        "param_distributions = {\n",
        "    'n_estimators': randint(50, 200),\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': randint(2, 11),\n",
        "    'min_samples_leaf': randint(1, 5)\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(RandomForestRegressor(random_state=42),\n",
        "                                    param_distributions,\n",
        "                                    n_iter=20,\n",
        "                                    cv=3,\n",
        "                                    scoring='neg_mean_squared_error',\n",
        "                                    n_jobs=-1,\n",
        "                                    random_state=42)\n",
        "\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "best_rf_model = random_search.best_estimator_\n",
        "best_params = random_search.best_params_\n",
        "print(\"\\nBest Parameters:\", best_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9ZCd6-dL9Vu",
        "outputId": "ff321490-84d7-4b50-abec-d9f587ff2172"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Parameters: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 124}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Model Evaluation:**\n",
        "- **Testing the Model:** The code uses the testing set to evaluate how well the model can predict house prices. It calculates several metrics, such as the Mean Squared Error (MSE) and R-squared, to measure the model's accuracy. The R-squared tells you how much of the variance in the house prices is explained by the model."
      ],
      "metadata": {
        "id": "tzGSUK6wLKJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation (on the test set)\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "y_rf_pred = best_rf_model.predict(X_test_scaled)\n",
        "rf_mse = mean_squared_error(y_test, y_rf_pred)\n",
        "rf_rmse = np.sqrt(rf_mse)\n",
        "rf_r2 = r2_score(y_test, y_rf_pred)\n",
        "\n",
        "print(\"\\nRandom Forest Regressor Model Evaluation (Tuned):\")\n",
        "print(\"Mean Squared Error:\", rf_mse)\n",
        "print(\"Root Mean Squared Error:\", rf_rmse)\n",
        "print(\"R-squared:\", rf_r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nnJnwKgL-E1",
        "outputId": "e0af74a3-4b81-47f4-d6de-c16e15c8be4d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest Regressor Model Evaluation (Tuned):\n",
            "Mean Squared Error: 21832650023.193043\n",
            "Root Mean Squared Error: 147758.75616420517\n",
            "R-squared: 0.8555819233183328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Feature Importance:**\n",
        "- **Figuring Out What Matters Most:** The code determines which features were most important in making predictions. This can give you insights into what aspects of a house have the biggest impact on its price."
      ],
      "metadata": {
        "id": "AjmG2AkKLKnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Importance\n",
        "feature_importances = best_rf_model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
        "feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False)\n",
        "print(\"\\nFeature Importances (Random Forest):\")\n",
        "print(feature_importance_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrB_qzbIL-9V",
        "outputId": "aa06aa31-e464-40c5-c213-59910b848e15"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature Importances (Random Forest):\n",
            "          Feature  Importance\n",
            "8           grade    0.318736\n",
            "2     sqft_living    0.277698\n",
            "14            lat    0.152921\n",
            "15           long    0.061868\n",
            "5      waterfront    0.030999\n",
            "16  sqft_living15    0.030321\n",
            "18            age    0.022729\n",
            "9      sqft_above    0.017443\n",
            "13        zipcode    0.013705\n",
            "3        sqft_lot    0.012033\n",
            "11       yr_built    0.011572\n",
            "17     sqft_lot15    0.010626\n",
            "1       bathrooms    0.010472\n",
            "6            view    0.010028\n",
            "10  sqft_basement    0.005253\n",
            "21     sale_month    0.004940\n",
            "7       condition    0.002354\n",
            "0        bedrooms    0.002233\n",
            "4          floors    0.001422\n",
            "12   yr_renovated    0.001185\n",
            "20      sale_year    0.001118\n",
            "19      renovated    0.000345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Saving the Model and Scaler:**\n",
        "- **Storing the Results:** The code saves the trained model and the scaler to files. This allows you to load the model and scaler later and use them to predict prices for new houses without having to retrain the model from scratch. Think of it as saving your perfect recipe so you can use it again and again."
      ],
      "metadata": {
        "id": "Necqc2nrLUN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Model and Scaler\n",
        "with open('model.pkl', 'wb') as f:\n",
        "    pickle.dump(best_rf_model, f)\n",
        "\n",
        "with open('scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "print(\"\\nModel and Scaler saved to model.pkl and scaler.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ApIEcx2L_ou",
        "outputId": "ad595590-d704-4076-ee9e-7335b3617c61"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model and Scaler saved to model.pkl and scaler.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import gzip\n",
        "\n",
        "# Save the Model with Gzip compression\n",
        "with gzip.open('model.pkl.gz', 'wb') as f:\n",
        "    pickle.dump(best_rf_model, f)\n",
        "\n",
        "# Save the Scaler with Gzip compression\n",
        "with gzip.open('scaler.pkl.gz', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "print(\"\\nModel and Scaler saved to model.pkl.gz and scaler.pkl.gz\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyjCnfcUr1uU",
        "outputId": "8a97eb23-dc13-41ca-d683-26bd084e36fb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model and Scaler saved to model.pkl.gz and scaler.pkl.gz\n"
          ]
        }
      ]
    }
  ]
}